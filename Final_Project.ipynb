{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import errno\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import ndimage\n",
    "\n",
    "# Use jupyter \"magic\" methods to dynamically reload external modules every\n",
    "# time any block is run, and show images inline in the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the source folder and exposure times to match your own\n",
    "# input images. Note that the response curve is calculated from\n",
    "# a random sampling of the pixels in the image, so there may be\n",
    "# variation in the output even for the example exposure stack\n",
    "SRC_FOLDER = \"images/source/original1\"\n",
    "OUT_FOLDER = \"images/output\"\n",
    "EXTENSIONS = set([\"bmp\", \"jpeg\", \"jpg\", \"png\", \"tif\", \"tiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_animation_frames(left_image, right_image, camera_angle, fov, distance_factor, num_int_frames, output_folder):\n",
    "    \"\"\" Generates intermediate frames that will be used to smooth out the transition between our two \n",
    "        stereo images in order to give a more credible 3d rotation or 'wiggle effect'.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        left_image: np.ndarray\n",
    "            First stereo image \n",
    "        right_image: np.ndarray\n",
    "            Second stereo image\n",
    "        camera_angle: int\n",
    "            Angle between left and right camera\n",
    "        fov: <int>\n",
    "            Field of view of camera\n",
    "        distance_factor: int\n",
    "            Distance parameter for better depth perception\n",
    "        num_int_frames: int\n",
    "            Number of intermediate frames we want to generate\n",
    "        output_folder: string\n",
    "            Directory where the resulting frames will be saved\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        frames: list<np.ndarray>\n",
    "            The set of resulting intermediate frames generated\n",
    "    \"\"\"\n",
    "    # Initialize output array\n",
    "    frames = []\n",
    "\n",
    "    # Generate angles for all intermediate frames\n",
    "    int_angles = np.linspace(0, camera_angle, num=num_int_frames, endpoint=False, dtype=np.float64)\n",
    "    \n",
    "    # To generate an infinite wiggle image duplicate intermediate frames\n",
    "    tot_frames = num_int_frames * 2\n",
    "        \n",
    "    # Generate intermediate frames and save output\n",
    "    for i in range(1,len(int_angles)):\n",
    "        # Extract intermediate image angle\n",
    "        int_cam_angle = int_angles[i]\n",
    "        \n",
    "        print \"Generating frame: '\" + str(i) + \" with angle \" + str(int_cam_angle) + \" ...\"\n",
    "        \n",
    "        # Generate intermediate frame\n",
    "        out = generate_intermediate_frame(left_image,right_image,camera_angle,int_cam_angle, fov, distance_factor)\n",
    "        \n",
    "        # Save the frame \n",
    "        cv2.imwrite(path.join(output_folder, \"frame\" + \"%03d\" % i + \".png\"), out)\n",
    "\n",
    "        # Save Duplicate frame to create gif\n",
    "        cv2.imwrite(path.join(output_folder, \"frame\" + \"%03d\" % (tot_frames - i) + \".png\"), out)\n",
    "            \n",
    "        # Append result to frames list\n",
    "        frames.append(out)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(image_files, output_folder, resize=False):\n",
    "    \"\"\" This function takes care of Setting up the input images in the direactory. \n",
    "        It is where camera and image parameters are adjusted. It also takes care \n",
    "        or saving frames and generating the resulting animation of our algorithm.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        image_files: \n",
    "        \n",
    "        output_folder:\n",
    "        \n",
    "        resize(False):\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    img_stack = [cv2.imread(name) for name in image_files\n",
    "                 if path.splitext(name)[-1][1:].lower() in EXTENSIONS]\n",
    "\n",
    "    if any([im is None for im in img_stack]):\n",
    "        raise RuntimeError(\"One or more input files failed to load.\")\n",
    "\n",
    "    # Subsampling the images can reduce runtime for large files\n",
    "    if resize:\n",
    "        img_stack = [img[::4, ::4] for img in img_stack]\n",
    "    \n",
    "    left_image = img_stack[0]\n",
    "    right_image = img_stack[1]\n",
    "    \n",
    "    # Parameters\n",
    "    camera_angle = 1.9#3.5#1.9\n",
    "    fov = 100\n",
    "    num_int_frames = 6\n",
    "    distance_factor = 1\n",
    "    \n",
    "    frames = generate_animation_frames(left_image, right_image, camera_angle, \n",
    "                                       fov, distance_factor, num_int_frames, output_folder)\n",
    "    \n",
    "    # Save initial and final frames to output directory\n",
    "    cv2.imwrite(path.join(output_folder, \"frame\" + \"%03d\" % 0 + \".png\"), left_image)\n",
    "    cv2.imwrite(path.join(output_folder, \"frame\" + \"%03d\" % (len(frames)+1) + \".png\"), right_image)\n",
    "    \n",
    "    # Convert frames to gif\n",
    "    command = \"ffmpeg -i \" + path.join(output_folder, \"frame%03d.png\") + \" -r 10 \" + path.join(output_folder, \"out_video.gif\")    \n",
    "    os.system(command)\n",
    "\n",
    "\n",
    "    print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\" Main function that takes care of reading through directory and running main \n",
    "        function with our read stereo image pair.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        Nothing\n",
    "    \"\"\"\n",
    "    src_contents = os.walk(SRC_FOLDER)\n",
    "    dirpath, _, fnames = src_contents.next()\n",
    "\n",
    "    image_dir = os.path.split(dirpath)[-1]\n",
    "    output_dir = os.path.join(OUT_FOLDER, image_dir)\n",
    "    print(output_dir)\n",
    "    try:\n",
    "        os.makedirs(output_dir)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "    print \"Processing '\" + image_dir + \"' folder...\"\n",
    "\n",
    "    image_files = sorted([os.path.join(dirpath, name) for name in fnames])\n",
    "    \n",
    "    main(image_files, output_dir, resize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/output/original4\n",
      "Processing 'original4' folder...\n",
      "Generating frame: '1 with angle 0.316666666667 ...\n",
      "('Pivot Distance: ', 255.0)\n",
      "('Number of holes', 1383)\n",
      "('Final Number of holes', 0)\n",
      "Generating frame: '2 with angle 0.633333333333 ...\n",
      "('Pivot Distance: ', 255.0)\n",
      "('Number of holes', 1458)\n",
      "('Final Number of holes', 0)\n",
      "Generating frame: '3 with angle 0.95 ...\n",
      "('Pivot Distance: ', 255.0)\n",
      "('Number of holes', 1461)\n",
      "('Final Number of holes', 0)\n",
      "Generating frame: '4 with angle 1.26666666667 ...\n",
      "('Pivot Distance: ', 255.0)\n",
      "('Number of holes', 1407)\n",
      "('Final Number of holes', 0)\n",
      "Generating frame: '5 with angle 1.58333333333 ...\n",
      "('Pivot Distance: ', 255.0)\n",
      "('Number of holes', 1416)\n",
      "('Final Number of holes', 0)\n",
      "ffmpeg -i images/output/original4/frame%03d.png -r 10 images/output/original4/out_video.gif\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate Frame Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_intermediate_frame(image_L,image_R,camera_angle,int_camera_angle,fov,distance_factor):\n",
    "    \"\"\"Computational pipeline to produce an intermediate image using a pivot point from a depth map\n",
    "    of a set of stereoscopic images.\n",
    "\n",
    "    The basic overview is to do the following for each pair of stereo images:\n",
    "\n",
    "    1. Generate a depth map\n",
    "       \n",
    "    2. Select a pivot point\n",
    "\n",
    "    3. Use pivot point as guide to shift the image into new orientation\n",
    "\n",
    "    4. Map pixel values to new orientation and return the intermediate image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_L : <numpy.ndarray>\n",
    "        The first stereo image\n",
    "    image_R : <numpy.ndarray>\n",
    "        The second stereo image\n",
    "    camera_angle: <int>\n",
    "        Angle between left and right camera\n",
    "    int_camera_angle: <int>\n",
    "        Angle of intermediate image from the left image\n",
    "    fov: <int>\n",
    "        Field of view of camera\n",
    "    distance_factor: <int>\n",
    "        Distance parameter for better depth perception\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The resulting intermediate image generated\n",
    "    \"\"\"\n",
    "    # Extract depth map\n",
    "    depth_map = cv2.imread(path.join(SRC_FOLDER, \"depth/depth_map.png\"), cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    depth_map = np.multiply(depth_map.astype(np.float64)-255, -1)\n",
    "#     depth_map = calc_depth_map(image_L, image_R) # Automatic\n",
    "    \n",
    "    # Select Pivot Distance\n",
    "    y = set(depth_map.flatten())\n",
    "    pivot_dist = (max(y) + min(y)) /2 #ndimage.median(depth_map) # median of all distance values\n",
    "    \n",
    "    # Shift depth_map values\n",
    "    depth_map = depth_map + pivot_dist*distance_factor\n",
    "    pivot_dist = pivot_dist + pivot_dist*distance_factor\n",
    "    print(\"Pivot Distance: \",pivot_dist)\n",
    "    \n",
    "    # Save images into array\n",
    "    image_list = [image_L, image_R]\n",
    "\n",
    "    # Matrices that (for each image) holds information on where to send each pixel for the intermediate image\n",
    "    dtype = [('image_idx', int), ('angle', float)]\n",
    "    values = [(0, int_camera_angle),(1, -(camera_angle-int_camera_angle))]\n",
    "    image_data = np.array(values, dtype=dtype)\n",
    "    \n",
    "    # Using the int camera angle, determine which camera is closest and use its image\n",
    "    image_data = np.sort(image_data,order='angle')\n",
    "    \n",
    "    # Extract image dimensions\n",
    "    rows, cols, channel = image_L.shape\n",
    "\n",
    "    # Initialize transport maps\n",
    "    transport_maps = np.zeros((2,rows,cols,2))\n",
    "\n",
    "    # Initialize output image\n",
    "    int_img = np.zeros((rows, cols, channel)) + np.nan\n",
    "    \n",
    "    # Using the depth map, order the pixels from furthest to closest\n",
    "    dtype = [('row', int), ('col', int), ('depth', np.int16)]\n",
    "    dr = np.arange(rows)\n",
    "    dc = np.arange(cols)\n",
    "    depth_map_dict = np.array(np.zeros(depth_map.shape), dtype=dtype)\n",
    "    depth_map_dict['row'] = dr[:,None]\n",
    "    depth_map_dict['col'] = dc\n",
    "    depth_map_dict['depth'] = depth_map\n",
    "    sorted_dm = np.sort(depth_map_dict.flatten(), order='depth')[::-1].reshape(rows,cols)\n",
    "    \n",
    "    # Generate Transport Maps\n",
    "    for i in range(2):\n",
    "        # Extract Values\n",
    "        image = image_list[image_data[i]['image_idx']]\n",
    "        int_cam_angle = image_data[i]['angle']\n",
    "        transport_map = transport_maps[i]\n",
    "        for k in range(rows): # Y values\n",
    "            for j in range(cols): # X values\n",
    "                (row,col) = (sorted_dm[k,j][0], sorted_dm[k,j][1])\n",
    "                \n",
    "                # Change pixels to FOV degrees\n",
    "                pixel_fov_deg = (float(col)/float(cols))*fov - (fov/2)\n",
    "                pixel_fov_rad = np.deg2rad(pixel_fov_deg)\n",
    "                pixel_dist = sorted_dm[k,j][2]\n",
    "                \n",
    "                # Calculate pixel angle and radius with pivot\n",
    "                r,theta_p = pivot_ang_rad(pixel_fov_rad,pivot_dist,pixel_dist)\n",
    "                \n",
    "                # Calculate pixel fov angle\n",
    "                int_fov_deg = adjusted_fov(r,theta_p,int_cam_angle, pivot_dist)\n",
    "                int_fov_deg = np.rad2deg(int_fov_deg) # Convert back to degrees\n",
    "                \n",
    "                # Convert intermediate field-of-view degrees back into pixel location values\n",
    "                x_pixel = (int_fov_deg+(fov/2))*cols/fov                \n",
    "                x_pixel = int(round(x_pixel))\n",
    "\n",
    "                # Check if x_pixel is within bounds \n",
    "                if not np.isnan(x_pixel) and x_pixel < cols and x_pixel > 0:\n",
    "                    transport_map[row,col] = [row, x_pixel]\n",
    "                    \n",
    "                    # Fill the black spots with the pixels of current stereo image\n",
    "                    int_img[row,x_pixel] = image[row,col]\n",
    "    \n",
    "    int_img = patch_holes(int_img)\n",
    "        \n",
    "    return int_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pivot_ang_rad(pixel_ang,pivot_dist,pixel_dist):\n",
    "    \"\"\"Calculates a pixels distance from the pivot and its angle of rotation around it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    # pixel_ang:\n",
    "        angle (radians) between pixel and pivot from camera\n",
    "    # pivot_dist:\n",
    "        distance from camera to pivot\n",
    "    # pixel_dist:\n",
    "        distance from camera to pixel\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    # r: distance from pivot\n",
    "    # angle: angle of rotation\n",
    "    \"\"\"\n",
    "    # Pixel at pivot angle case\n",
    "    if (pixel_ang == 0):\n",
    "        dist = pivot_dist - pixel_dist\n",
    "        # Pixel is in front of pivot\n",
    "        if (dist >= 0):\n",
    "            angle =  np.deg2rad(0)\n",
    "        # Pixel is behind the pivot\n",
    "        else:\n",
    "            angle = np.deg2rad(180)\n",
    "        r = abs(dist)\n",
    "        return(r,angle)\n",
    "    \n",
    "    # Normal Case\n",
    "    else:\n",
    "        x = pixel_dist*np.sin(pixel_ang) \n",
    "        y = pixel_dist*np.cos(pixel_ang)\n",
    "        z = pivot_dist - y\n",
    "        \n",
    "        # Case where inv tan can't be computed\n",
    "        if (z == 0):\n",
    "            r = abs(x)\n",
    "            if (x > 0):\n",
    "                angle = np.deg2rad(90)\n",
    "            else:\n",
    "                angle = np.deg2rad(-90)\n",
    "            return(r,angle)\n",
    "        \n",
    "        # Case where inv tan can be computed\n",
    "        angle = np.arctan(x/z)\n",
    "        r = np.sqrt(x**2 + z**2)\n",
    "        if (z < 0):\n",
    "            angle = angle + np.deg2rad(180)\n",
    "        return(r.astype(np.float64),angle.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjusted_fov(r,pixel_ang,int_cam_angle, pivot_dist):\n",
    "    \"\"\" Calculates FOV angle for pixel in the intermediate camera\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    # r: \n",
    "        distance from pixel to pivot point\n",
    "    # angle:\n",
    "        angle the pixel is rotated from center in the camera\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    # angle: FOV angle\n",
    "    \"\"\"\n",
    "    \n",
    "    #Convert int_cam_angle to Rad\n",
    "    int_cam_angle = np.deg2rad(int_cam_angle)\n",
    "    \n",
    "    # Calculate relative rotation of pixel for intermediate camera's pov\n",
    "    i_angle = pixel_ang - int_cam_angle\n",
    "    \n",
    "    # Case where new pixel rotation is right in front or behind pivot axis\n",
    "    if (i_angle % np.deg2rad(180) == 0):\n",
    "        angle = 0.0\n",
    "        return(angle)\n",
    "        \n",
    "    # Normal Case\n",
    "    x = r * np.sin(i_angle)\n",
    "    y = r * np.cos(i_angle)\n",
    "    z = pivot_dist - y\n",
    "    \n",
    "    # Arctan will always evaluate since z != 0\n",
    "    angle = np.arctan(x/z)\n",
    "    return(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patch_holes(image):\n",
    "    \"\"\" Helper function that takes care of interpolating pixel values that were not\n",
    "        able to be assigned during our remapping algorithm for the intermediate image.\n",
    "        \n",
    "        Parameter:\n",
    "        ----------\n",
    "        image: numpy.ndarray\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        out: numpy.ndarray\n",
    "        Patched image with interpolated pixel values in 'holes' or unasigned pixels.\n",
    "    \"\"\"\n",
    "    # Extract image dimensions\n",
    "    rows, cols, channels = image.shape\n",
    "    \n",
    "    # Check for any left over holes and if there are any fill in remaining pixels\n",
    "#     print(\"Number of holes\", np.count_nonzero(np.isnan(image)))\n",
    "    \n",
    "    # If there are remaining nan values, replace them by interpolating amongst neighbors\n",
    "    if (np.count_nonzero(np.isnan(image)) > 0):\n",
    "         for i in range(rows): # Y values\n",
    "            for j in range(cols): # X values\n",
    "                # If this pixel is nan, interpolate from neighbors to replace value\n",
    "                if(np.isnan(image[i,j]).all()):\n",
    "                    # Find closest indexes to pixel that is not nan\n",
    "                    left_cols = image[i,0:j]\n",
    "                    right_cols = image[i,j+1:cols]\n",
    "                    \n",
    "                    # Make sure l_idx and r_ix are valid values\n",
    "                    try:\n",
    "                        l_idx = np.nanargmax(left_cols[:,0])\n",
    "                        l_w = float(1.0)\n",
    "                    except:\n",
    "                        left_cols = np.zeros((1,channels))\n",
    "                        l_idx = 0\n",
    "                        l_w = float(0.0)\n",
    "                    try:\n",
    "                        r_idx = np.nanargmin(right_cols[:,0])\n",
    "                        r_w = float(1.0)\n",
    "                    except:\n",
    "                        right_cols = np.zeros((1,channels))\n",
    "                        r_idx = 0\n",
    "                        r_w = float(0.0)\n",
    "                    \n",
    "                    # Fill spot using neighboring columns\n",
    "                    image[i,j] = [np.average([left_cols[l_idx,x], right_cols[r_idx,x]], weights=[l_w, r_w]) for x in range(channels)]\n",
    "    \n",
    "#     print(\"Final Number of holes\", np.count_nonzero(np.isnan(image)))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Optical Flow Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_optical_flow(img1, img2):\n",
    "    \"\"\" Calculates optical flow from a pair of stereo images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    # img_l: <np.ndarray>\n",
    "        First stereo image\n",
    "        \n",
    "    # img_r: <np.ndarray>\n",
    "        Second stereo image\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    optical flow map: <numpy.ndarray>\n",
    "         \n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    hsv = np.zeros_like(img1)\n",
    "    # Convert images to single channel by making grayscale\n",
    "    gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # while(1):\n",
    "    # Gunnar Farnebäck. Two-frame motion estimation based on polynomial expansion. In Image Analysis, pages 363–370. Springer, 2003.\n",
    "    # img1, img2, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags\n",
    "    # defaults: flow=None, pyr_scale=0.5, poly_n=5 or 7, poly_n=5, use poly_sigma=1.1, poly_n=7, use poly_sigma=1.5\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1,gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # show hsv as bgr color image\n",
    "    hsv[...,1] = 255\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_depth_map(img_l, img_r):\n",
    "    \"\"\" Calculates depth map from a set of stereo images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    # img_l: <np.ndarray>\n",
    "        First stereo image\n",
    "        \n",
    "    # img_r: <np.ndarray>\n",
    "        Second stereo image\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    depth_map: <numpy.ndarray>\n",
    "        Grayscale image with depth values at each pixel\n",
    "    \"\"\"\n",
    "    # Get output directory\n",
    "    src_contents = os.walk(SRC_FOLDER)\n",
    "    dirpath, _, fnames = src_contents.next()\n",
    "\n",
    "    image_dir = os.path.split(dirpath)[-1]\n",
    "    output_dir = os.path.join(OUT_FOLDER, image_dir)\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    gray1 = cv2.cvtColor(img_l,cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img_r,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blur the images\n",
    "    gray1 = cv2.GaussianBlur(gray1,(5,5),0)\n",
    "    gray2 = cv2.GaussianBlur(gray2,(5,5),0)\n",
    "    \n",
    "    # Calculate disparity \n",
    "    #ndisparities should be divisible by 16, SADWindowSize should be odd\n",
    "    stereo = cv2.StereoBM(cv2.STEREO_BM_BASIC_PRESET,ndisparities=16, SADWindowSize=51)\n",
    "    disparity = stereo.compute(gray1,gray2).astype(np.float64) # 16, 101\n",
    "    \n",
    "    if np.min(disparity) < 0:\n",
    "        # Shift disparity to be centered\n",
    "        disparity = np.add(disparity, abs(np.min(disparity)))\n",
    "        \n",
    "    # Normalize results\n",
    "    out = cv2.normalize(disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Save results\n",
    "    cv2.imwrite(path.join(output_dir, \"depth_map.png\"), out)\n",
    "    \n",
    "    # Adjust Values\n",
    "    return np.multiply(out-255, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Energy Computations\n",
    "\"\"\" \"\"\"\n",
    "\n",
    "# Depth Energy\n",
    "def calc_depth_energy(depth_map):\n",
    "    \"\"\" Will be calculated based on a preference for position the pivot point on regions\n",
    "        close to the middle of the depth map\n",
    "\n",
    "    Depth Energy: We use the depth energy to express a preference\n",
    "    for positioning the pivot point on regions that are\n",
    "    close to the middle of the depth map. This minimizes the\n",
    "    visibility of the occluded regions during the rendering camera\n",
    "    movements and also lowers the amount of motion when\n",
    "    the final animation is generated. We obtain the depth map\n",
    "    of a given image set by calculating its optical flow using\n",
    "    Sun et al.’s [48] algorithm. Details about depth map calculation\n",
    "    are described in Section 8. After calculating the\n",
    "    depth map we can calculate the depth energy as: \n",
    "    Ed(x, y) = ||Pd(x, y)−Dm||2\n",
    "        where Pd(x, y) refers to the depth value of the pixel at (x, y) \n",
    "        and Dm is the median depth of the scene.\n",
    "    \"\"\"\n",
    "    median_depth = ndimage.median(depth_map)\n",
    "\n",
    "    depth_energy = np.sqrt((depth_map - median_depth)**2)\n",
    "\n",
    "    return depth_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saliency Energy\n",
    "def calc_saliency_energy(img):\n",
    "    \"\"\" \"\"\"\n",
    "    # Change input to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize saliency algorithm\n",
    "\n",
    "    saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "    saliency.setImagesize(img.shape)\n",
    "    saliency.init()\n",
    "    \n",
    "    # Run algorithm\n",
    "    out, saliencyMap = saliency.computeSaliency(gray)\n",
    "    cv2.imwrite(path.join(OUT_FOLDER, \"source/saliency_energy.png\"), (1 - out))\n",
    "\n",
    "    return (1 - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Radial Energy\n",
    "def calc_radial_energy(img):\n",
    "    \"\"\" \"\"\"\n",
    "    # Calculate center of image\n",
    "    cx, cy = img.shape // 2\n",
    "\n",
    "    # Generate Coordinate vectors\n",
    "    nx, ny = img.shape\n",
    "    x = np.arange(nx)\n",
    "    y = np.arange(ny)\n",
    "    xcoords, ycoords = np.meshgrid(x, y)\n",
    "\n",
    "    # Calculate Radial Energy for each pixel\n",
    "    # E(x,y) = sqrt((cx-x)^2 + (cy-y)^2)\n",
    "    radial_energy = np.sqrt((cx - xcoords)**2 + (cy - ycoords)**2)\n",
    "\n",
    "    return radial_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code Out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CompPhoto]",
   "language": "python",
   "name": "conda-env-CompPhoto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
